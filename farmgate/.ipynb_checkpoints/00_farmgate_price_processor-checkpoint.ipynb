{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp farm_gate_price_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from fastcore.script import *\n",
    "import click\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def not_empty(row):\n",
    "    x = \"\".join(row)\n",
    "    if len(x) > 0: \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_brand_row(line_groups):\n",
    "    line_groups[0].remove('\"Ministry of Industry,\\n')\n",
    "    return line_groups   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_parishes(dct):\n",
    "    parishes = []\n",
    "    ps = dct[2]\n",
    "    for i in ps:\n",
    "        if len(i.strip()) > 5:\n",
    "            parishes.append(i)\n",
    "            \n",
    "    return parishes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_empty_strings_from_data_rows(lst):\n",
    "    new_lst = [] \n",
    "    for item in lst: \n",
    "        if len(item) > 0: \n",
    "            new_lst.append(item)\n",
    "           \n",
    "    return new_lst\n",
    "\n",
    "def get_data(list_of_lines, number_of_parishes):\n",
    "    data = []\n",
    "   \n",
    "    for line in list_of_lines:\n",
    "        lst = line.split(\"|\")\n",
    "        l = len(lst)\n",
    "        lst = remove_empty_strings_from_data_rows(lst)\n",
    "        if len(lst) == 8 and number_of_parishes == 1:\n",
    "            # then pad the list\n",
    "            # remove the newline character at the end first\n",
    "            lst.remove(\"\\n\")\n",
    "            lst.extend(5*\"-\".split())\n",
    "        try:\n",
    "            lst.remove(\"-\\n\")\n",
    "            lst.append(\"-\")\n",
    "        except:\n",
    "            pass\n",
    "        data.append(lst)\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_date(date):\n",
    "    date = date.lower().replace(\" \", \"_\").replace(\",\",\"\")\n",
    "    return date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_headers(list_of_lines):\n",
    "    lst = []\n",
    "    for line in list_of_lines:\n",
    "        lst.append(line.split(\"|\"))\n",
    "    lst = flatten_list(lst)\n",
    "    lst = remove_empty_strings_from_list(lst)\n",
    "    lst_copy = lst.copy()\n",
    "    commodity = lst_copy[12]\n",
    "    variety_source = lst_copy[13] + \" \" + lst_copy[15]\n",
    "    most_frequent = lst_copy[2] + \" \" + lst_copy[3]\n",
    "    lst[:0] = [variety_source] \n",
    "    lst[:0] = [commodity]\n",
    "    lst[:0] = ['parish']\n",
    "    lst[:0] = ['date']\n",
    "    lst.insert(6,most_frequent)\n",
    "    del lst[7]\n",
    "    del lst[7]\n",
    "    lst.insert(11,most_frequent)\n",
    "    del lst[12]\n",
    "    del lst[12]\n",
    "    # format the list\n",
    "    lst = list(map(str.lower, lst))\n",
    "    lst = list(map( lambda s: s.replace('\"',''), lst ))\n",
    "    return lst[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_date(raw_date_string):\n",
    "    clean_date_string = (raw_date_string\n",
    "                         .replace(\"Week\",\"\")\n",
    "                         .replace(\"Ending\",\"\")\n",
    "                         .replace(\"|\", \"\")\n",
    "                         .replace('\"',\"\")).rstrip()\n",
    "    return clean_date_string.lstrip()\n",
    "\n",
    "s = clean_date('Week Ending September 04, 2021\"||||||||||||||||\\n')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ParishData:\n",
    "   \n",
    "    def __init__(self, parish, data, header):\n",
    "        self.parish = parish.replace(\" \",\"\").lower()\n",
    "        self.data = data\n",
    "        self.header = header\n",
    "        \n",
    "    def write_to_csv(self,output_directory:str):\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        try:\n",
    "            os.mkdir(f\"{output_directory}/{report_date}\") \n",
    "        except OSError as error: \n",
    "            print(f\"{output_directory}/{report_date} already exists,not recreating\")      \n",
    "\n",
    "        self.data.insert(0,self.header)\n",
    "        df = pd.DataFrame(self.data)\n",
    "        df.to_csv(f\"{output_directory}/{report_date}/{self.parish}_{report_date}.csv\",sep=\"|\" ,index=False, header=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.parish}: {self.data}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def flatten_list(lst):\n",
    "    flat_list = [item for sublist in lst for item in sublist] \n",
    "    return flat_list \n",
    "\n",
    "def remove_empty_strings_from_list(lst):\n",
    "    _list = ' '.join(lst).split()\n",
    "    return _list \n",
    "\n",
    "def create_parish_data(data_list,data_date,header,parish):\n",
    "    result = ParishData(parish, data_list, header)    \n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_data(data_list,idx,parish_list,date):\n",
    "    idx = 7\n",
    "    r = []\n",
    "    p0_data_list = []\n",
    "    p1_data_list = []\n",
    "    for d in data_list: \n",
    "        d = list(map( lambda s: s.replace('\\n',''), d ))\n",
    "        d = list(map(str.lower, d))\n",
    "        if len(parish_list) == 2:\n",
    "            p1 = parish_list[0]\n",
    "            p2 = parish_list[1]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            d2 = d[idx:]\n",
    "            # let add the variety\n",
    "            d2[:0] = [d[1]]\n",
    "            # and the commodity\n",
    "            d2[:0] = [d[0]]\n",
    "            d2[:0] =  [p2]\n",
    "            d2[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "            p1_data_list.extend([d2])\n",
    "            x = f\"{len(p0_data_list[0])}, {p0_data_list}\",f\"{len(p1_data_list[0])}, {p1_data_list}\"\n",
    "            \n",
    "        else: \n",
    "            p1 = parish_list[0]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "    if len(parish_list) == 2:\n",
    "        result = p0_data_list, p1_data_list\n",
    "    else: \n",
    "        result = p0_data_list\n",
    "        \n",
    "    return  result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_group(group,header):\n",
    "        data_group_list = []\n",
    "        result = []\n",
    "        parishes_no_space  = {}\n",
    "        idx = 0\n",
    "        \n",
    "        parish_list = [\"Manchester\",\n",
    "                       \"St.Andrew\",\n",
    "                       \"St.Catherine\",\n",
    "                       \"Clarendon\",\n",
    "                       \"St.Elizabeth\",\n",
    "                       \"Westmoreland\",\n",
    "                       \"Hanover\",\n",
    "                       \"St.James\",\n",
    "                       \"Trelawny\",\n",
    "                       \"St.Ann\",\n",
    "                       \"St.Mary\",\n",
    "                       \"Portland\",\n",
    "                       \"St.Thomas\"]   \n",
    "        parishes = group[0]\n",
    "        parishes = parishes.split(\"|\")\n",
    "        for p in parishes: \n",
    "            if len(p) > 5:\n",
    "                parishes_no_space[idx]  = p\n",
    "                idx = idx + 1\n",
    "        # there is space between the manchester and st.andrew heading\n",
    "        # and thier data, this space is not between the other headers \n",
    "        # and thier data :-) \n",
    "        offset =  5 if len(group) == 55 else 3        \n",
    "        \n",
    "        data_list = get_data(group[offset:],len(parishes_no_space)) \n",
    "             \n",
    "        \n",
    "        if len(parishes_no_space) == 2: \n",
    "            p1 = parishes_no_space[0]\n",
    "            p2 = parishes_no_space[1]\n",
    "            # split the data\n",
    "            p1_data, p2_data = split_data(data_list,idx,[p1,p2],report_date)\n",
    "            parish_data_1 = create_parish_data(p1_data,report_date , header,p1)\n",
    "            parish_data_2 = create_parish_data(p2_data,report_date , header,p2)\n",
    "            result.extend([parish_data_1,parish_data_2])\n",
    "        else:\n",
    "            # we only have one parish \n",
    "            p1 = parishes_no_space[0]\n",
    "            p1_data = split_data(data_list,idx,[p1],report_date)\n",
    "            parish_data_1 = create_parish_data( p1_data ,report_date, header,p1)\n",
    "            result.extend([parish_data_1])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "group = []  \n",
    "header = ['date', 'parish', 'Commodity', 'Variety Source', \n",
    "'Low', 'High', '\"Most Frequent\"', 'Supply', 'Grade', 'Low', \n",
    "'High', '\"Most Frequent\"', 'Supply', 'Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "global report_date  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def combine_parish_data(parish_data_list:list):\n",
    "    \"\"\"\n",
    "    Combine multiple parish  objects into a single \n",
    "    Parish object. The new parish object has a\n",
    "    single header\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parish_data_list: list\n",
    "    A list of parish data objects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    ParishData\n",
    "\n",
    "    The combination of all the objects\n",
    "    in the parish_data_list          \n",
    "\n",
    "    \"\"\"\n",
    "    header = parish_data_list[0].header\n",
    "    combine_data = []\n",
    "    for p in parish_data_list:\n",
    "        # remove the header row\n",
    "        combine_data.extend(p.data)\n",
    "   \n",
    "    p_data = ParishData(\"all\",combine_data, header)\n",
    "    return  p_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_farm_gate_data(input_path:str, output_directory:str):\n",
    "    global report_date\n",
    "    path = input_path\n",
    "    with open(path) as file:\n",
    "        groups =[]\n",
    "        processed_groups = []\n",
    "        current_group =[]\n",
    "        \n",
    "        group_boundary_str = \"Prepared on\"\n",
    "        doc_lines = file.readlines()\n",
    "        for line in doc_lines:\n",
    "            if \"Ministry of Industry\" in line:\n",
    "                continue\n",
    "            if \"Fisheries\" in line:\n",
    "                continue\n",
    "            if \"Commerce, Agriculture\" in line:\n",
    "                continue    \n",
    "            if \"Prepared on\" in line:\n",
    "                groups.append(current_group)\n",
    "                current_group = []\n",
    "                continue\n",
    "            if len(line.replace(\"|\", \"\").strip()) == 0:\n",
    "                continue \n",
    "            if  \"Week Ending\" in line:\n",
    "                report_date = clean_date(line)\n",
    "                report_date =format_date(report_date)\n",
    "                continue\n",
    "            current_group.append(line)\n",
    "    \n",
    "    headers = get_headers(groups[0][1:5])\n",
    "        \n",
    "    for group in groups:\n",
    "        group = process_group(group, headers)\n",
    "        processed_groups.append(group)\n",
    "        \n",
    "    flat_list = [item for sublist in processed_groups for item in sublist]  \n",
    "\n",
    "    parish_data = combine_parish_data(flat_list)\n",
    "    parish_data.write_to_csv(output_directory)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
