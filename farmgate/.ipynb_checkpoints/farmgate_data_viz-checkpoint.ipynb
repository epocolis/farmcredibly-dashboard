{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import * \n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_empty(row):\n",
    "    x = \"\".join(row)\n",
    "    if len(x) > 0: \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brand_row(line_groups):\n",
    "    line_groups[0].remove('\"Ministry of Industry,\\n')\n",
    "    return line_groups   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parishes(dct):\n",
    "    parishes = []\n",
    "    ps = dct[2]\n",
    "    for i in ps:\n",
    "        if len(i.strip()) > 5:\n",
    "            parishes.append(i)\n",
    "            \n",
    "    return parishes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_strings_from_data_rows(lst):\n",
    "    new_lst = [] \n",
    "    for item in lst: \n",
    "        if len(item) > 0: \n",
    "            new_lst.append(item)\n",
    "           \n",
    "    return new_lst\n",
    "\n",
    "def get_data(list_of_lines, number_of_parishes):\n",
    "    data = []\n",
    "   \n",
    "    for line in list_of_lines:\n",
    "        lst = line.split(\"|\")\n",
    "        l = len(lst)\n",
    "        lst = remove_empty_strings_from_data_rows(lst)\n",
    "        if len(lst) == 8 and number_of_parishes == 1:\n",
    "            # then pad the list\n",
    "            # remove the newline character at the end first\n",
    "            lst.remove(\"\\n\")\n",
    "            lst.extend(5*\"-\".split())\n",
    "        try:\n",
    "            lst.remove(\"-\\n\")\n",
    "            lst.append(\"-\")\n",
    "        except:\n",
    "            pass\n",
    "        data.append(lst)\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(list_of_lines):\n",
    "    lst = []\n",
    "    for line in list_of_lines:\n",
    "        lst.append(line.split(\"|\"))\n",
    "    lst = flatten_list(lst)\n",
    "    lst = remove_empty_strings_from_list(lst)\n",
    "    lst_copy = lst.copy()\n",
    "    commodity = lst_copy[12]\n",
    "    variety_source = lst_copy[13] + \" \" + lst_copy[15]\n",
    "    most_frequent = lst_copy[2] + \" \" + lst_copy[3]\n",
    "    lst[:0] = [variety_source] \n",
    "    lst[:0] = [commodity]\n",
    "    lst[:0] = ['parish']\n",
    "    lst[:0] = ['date']\n",
    "    lst.insert(6,most_frequent)\n",
    "    del lst[7]\n",
    "    del lst[7]\n",
    "    lst.insert(11,most_frequent)\n",
    "    del lst[12]\n",
    "    del lst[12]\n",
    "    # format the list\n",
    "    lst = list(map(str.lower, lst))\n",
    "    lst = list(map( lambda s: s.replace('\"',''), lst ))\n",
    "    return lst[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 04, 2021\n"
     ]
    }
   ],
   "source": [
    "def clean_date(raw_date_string):\n",
    "    clean_date_string = (raw_date_string\n",
    "                         .replace(\"Week\",\"\")\n",
    "                         .replace(\"Ending\",\"\")\n",
    "                         .replace(\"|\", \"\")\n",
    "                         .replace('\"',\"\")).rstrip()\n",
    "    return clean_date_string.lstrip()\n",
    "\n",
    "s = clean_date('Week Ending September 04, 2021\"||||||||||||||||\\n')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParishData:\n",
    "   \n",
    "    def __init__(self, parish, data, header):\n",
    "        self.parish = parish\n",
    "        self.data = data\n",
    "        self.header = header\n",
    "        \n",
    "    def write_to_csv(self):\n",
    "        import pandas as pd\n",
    "        self.data.insert(0,self.header)\n",
    "        df = pd.DataFrame(self.data)\n",
    "        df.to_csv(f\"{self.parish}.csv\",sep=\"|\" ,index=False, header=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.to_csv()}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'St.Thomas'} , [[1, 2, 3, 4], [5, 6, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "def flatten_list(lst):\n",
    "    flat_list = [item for sublist in lst for item in sublist] \n",
    "    return flat_list \n",
    "\n",
    "def remove_empty_strings_from_list(lst):\n",
    "    _list = ' '.join(lst).split()\n",
    "    return _list \n",
    "\n",
    "# parish_data_1 = create_parish_data(p1_data,report_date , header,p1)\n",
    "\n",
    "def create_parish_data(data_list,data_date,header,parish):\n",
    "    result = ParishData(parish, data_list, header)    \n",
    "    return result\n",
    "\n",
    "\n",
    "data_list = [[1,2,3,4],[5,6,7,8], \"12/12/2020\",[\"h1\",\"h2\",\"h3\"],{0:\"St.Thomas\"}]\n",
    "print(create_parish_data([[1,2,3,4],[5,6,7,8]],\"12/12/2020\",[\"h1\",\"h2\",\"h3\"],{0:\"St.Thomas\"}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['12/10/2222', 'p1', 'broccoli', 'local', '-', '-', '-', '-', '-']], [['12/10/2222', 'p2', 'broccoli', 'local', '1100', '1100', '1100', 'fair', 'excellent']])\n"
     ]
    }
   ],
   "source": [
    "def split_data(data_list,idx,parish_list,date):\n",
    "    idx = 7\n",
    "    r = []\n",
    "    p0_data_list = []\n",
    "    p1_data_list = []\n",
    "    for d in data_list: \n",
    "        d = list(map( lambda s: s.replace('\\n',''), d ))\n",
    "        d = list(map(str.lower, d))\n",
    "        if len(parish_list) == 2:\n",
    "            p1 = parish_list[0]\n",
    "            p2 = parish_list[1]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            d2 = d[idx:]\n",
    "            # let add the variety\n",
    "            d2[:0] = [d[1]]\n",
    "            # and the commodity\n",
    "            d2[:0] = [d[0]]\n",
    "            d2[:0] =  [p2]\n",
    "            d2[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "            p1_data_list.extend([d2])\n",
    "            x = f\"{len(p0_data_list[0])}, {p0_data_list}\",f\"{len(p1_data_list[0])}, {p1_data_list}\"\n",
    "            \n",
    "        else: \n",
    "            p1 = parish_list[0]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "    if len(parish_list) == 2:\n",
    "        result = p0_data_list, p1_data_list\n",
    "    else: \n",
    "        result = p0_data_list\n",
    "        \n",
    "    return  result\n",
    "        \n",
    "d_list = [['Broccoli', 'Local', '-', '-', '-', '-', '-', '1100', '1100', '1100', 'Fair', 'Excellent\\n']]   \n",
    "result = split_data(d_list,5, [\"p1\", \"p2\"], \"12/10/2222\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    " def process_group(group,header):\n",
    "        data_group_list = []\n",
    "        result = []\n",
    "        parishes_no_space  = {}\n",
    "        idx = 0\n",
    "        \n",
    "        parish_list = [\"Manchester\",\n",
    "                       \"St.Andrew\",\n",
    "                       \"St.Catherine\",\n",
    "                       \"Clarendon\",\n",
    "                       \"St.Elizabeth\",\n",
    "                       \"Westmoreland\",\n",
    "                       \"Hanover\",\n",
    "                       \"St.James\",\n",
    "                       \"Trelawny\",\n",
    "                       \"St.Ann\",\n",
    "                       \"St.Mary\",\n",
    "                       \"Portland\",\n",
    "                       \"St.Thomas\"]   \n",
    "        parishes = group[0]\n",
    "        parishes = parishes.split(\"|\")\n",
    "        for p in parishes: \n",
    "            if len(p) > 5:\n",
    "                parishes_no_space[idx]  = p\n",
    "                idx = idx + 1\n",
    "        # there is space between the manchester and st.andrew heading\n",
    "        # and thier data, this space is not between the other headers \n",
    "        # and thier data :-) \n",
    "        offset =  5 if len(group) == 55 else 3        \n",
    "        \n",
    "        data_list = get_data(group[offset:],len(parishes_no_space)) \n",
    "             \n",
    "        \n",
    "        if len(parishes_no_space) == 2: \n",
    "            p1 = parishes_no_space[0]\n",
    "            p2 = parishes_no_space[1]\n",
    "            # split the data\n",
    "            p1_data, p2_data = split_data(data_list,idx,[p1,p2],report_date)\n",
    "            parish_data_1 = create_parish_data(p1_data,report_date , header,p1)\n",
    "            parish_data_2 = create_parish_data(p2_data,report_date , header,p2)\n",
    "            result.extend([parish_data_1,parish_data_2])\n",
    "        else:\n",
    "            # we only have one parish \n",
    "            p1 = parishes_no_space[0]\n",
    "            p1_data = split_data(data_list,idx,[p1],report_date)\n",
    "            parish_data_1 = create_parish_data( p1_data ,report_date, header,p1)\n",
    "            result.extend([parish_data_1])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "group = []  \n",
    "header = ['date', 'parish', 'Commodity', 'Variety Source', 'Low', 'High', '\"Most Frequent\"', 'Supply', 'Grade', 'Low', 'High', '\"Most Frequent\"', 'Supply', 'Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv  xls\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/raw/farmgate_prices_2020_2021/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_date  = None\n",
    "\"\"\"\n",
    "Enter the name of the file here\n",
    "\"\"\"\n",
    "with open('Farmgate 09.04.2021.csv') as file:\n",
    "    groups =[]\n",
    "    processed_groups = []\n",
    "    current_group =[]\n",
    "    \n",
    "    group_boundary_str = \"Prepared on\"\n",
    "    doc_lines = file.readlines()\n",
    "    for line in doc_lines:\n",
    "        if \"Ministry of Industry\" in line:\n",
    "            continue\n",
    "        if \"Fisheries\" in line:\n",
    "            continue\n",
    "        if \"Commerce, Agriculture\" in line:\n",
    "            continue    \n",
    "        if \"Prepared on\" in line:\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "            continue\n",
    "        if len(line.replace(\"|\", \"\").strip()) == 0:\n",
    "            continue \n",
    "        if  \"Week Ending\" in line:\n",
    "            report_date = clean_date(line)\n",
    "            continue\n",
    "        current_group.append(line)\n",
    "    \n",
    "    headers = get_headers(groups[0][1:5])\n",
    "        \n",
    "    for group in groups:\n",
    "        group = process_group(group, headers)\n",
    "        processed_groups.append(group)\n",
    "        \n",
    "    flat_list = [item for sublist in processed_groups for item in sublist]    \n",
    "    for p in flat_list:\n",
    "        p.write_to_csv()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clarendon.csv\t\t\t   'St. Ann.csv'\r\n",
      "'Farmgate 09.04.2021.csv'\t   'St. Catherine.csv'\r\n",
      " Farmgate09.04.2021_processed.csv  'St. Elizabeth.csv'\r\n",
      " Farmgate09.04.2021_processed.xls  'St. James.csv'\r\n",
      "'Farmgate 09.04.2021.xls'\t   'St. Mary.csv'\r\n",
      " farmgate_data_viz.ipynb\t   'St. Thomas.csv'\r\n",
      " Hanover.csv\t\t\t    Trelawny.csv\r\n",
      " Manchester.csv\t\t\t   'Urban Municipal 09.04.2021.xls'\r\n",
      " Portland.csv\t\t\t    Westmoreland.csv\r\n",
      "'Retail 09.04.2021.xls'\t\t   'Wholesale 09.04.2021.pdf'\r\n",
      "'St. Andrew.csv'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
