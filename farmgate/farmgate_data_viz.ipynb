{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# default_exp agricultural_pricing_analytics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from fastcore.script import *\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#export\n",
    "def not_empty(row):\n",
    "    x = \"\".join(row)\n",
    "    if len(x) > 0: \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#export\n",
    "def remove_brand_row(line_groups):\n",
    "    line_groups[0].remove('\"Ministry of Industry,\\n')\n",
    "    return line_groups   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#export\n",
    "def get_parishes(dct):\n",
    "    parishes = []\n",
    "    ps = dct[2]\n",
    "    for i in ps:\n",
    "        if len(i.strip()) > 5:\n",
    "            parishes.append(i)\n",
    "            \n",
    "    return parishes\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#export\n",
    "def remove_empty_strings_from_data_rows(lst):\n",
    "    new_lst = [] \n",
    "    for item in lst: \n",
    "        if len(item) > 0: \n",
    "            new_lst.append(item)\n",
    "           \n",
    "    return new_lst\n",
    "\n",
    "def get_data(list_of_lines, number_of_parishes):\n",
    "    data = []\n",
    "   \n",
    "    for line in list_of_lines:\n",
    "        lst = line.split(\"|\")\n",
    "        l = len(lst)\n",
    "        lst = remove_empty_strings_from_data_rows(lst)\n",
    "        if len(lst) == 8 and number_of_parishes == 1:\n",
    "            # then pad the list\n",
    "            # remove the newline character at the end first\n",
    "            lst.remove(\"\\n\")\n",
    "            lst.extend(5*\"-\".split())\n",
    "        try:\n",
    "            lst.remove(\"-\\n\")\n",
    "            lst.append(\"-\")\n",
    "        except:\n",
    "            pass\n",
    "        data.append(lst)\n",
    "    return data\n",
    "        \n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "#export\n",
    "def format_date(date):\n",
    "    date = date.lower().replace(\" \", \"_\").replace(\",\",\"\")\n",
    "    return date\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "august_07_2021\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#export\n",
    "def get_headers(list_of_lines):\n",
    "    lst = []\n",
    "    for line in list_of_lines:\n",
    "        lst.append(line.split(\"|\"))\n",
    "    lst = flatten_list(lst)\n",
    "    lst = remove_empty_strings_from_list(lst)\n",
    "    lst_copy = lst.copy()\n",
    "    commodity = lst_copy[12]\n",
    "    variety_source = lst_copy[13] + \" \" + lst_copy[15]\n",
    "    most_frequent = lst_copy[2] + \" \" + lst_copy[3]\n",
    "    lst[:0] = [variety_source] \n",
    "    lst[:0] = [commodity]\n",
    "    lst[:0] = ['parish']\n",
    "    lst[:0] = ['date']\n",
    "    lst.insert(6,most_frequent)\n",
    "    del lst[7]\n",
    "    del lst[7]\n",
    "    lst.insert(11,most_frequent)\n",
    "    del lst[12]\n",
    "    del lst[12]\n",
    "    # format the list\n",
    "    lst = list(map(str.lower, lst))\n",
    "    lst = list(map( lambda s: s.replace('\"',''), lst ))\n",
    "    return lst[:9]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#export\n",
    "def clean_date(raw_date_string):\n",
    "    clean_date_string = (raw_date_string\n",
    "                         .replace(\"Week\",\"\")\n",
    "                         .replace(\"Ending\",\"\")\n",
    "                         .replace(\"|\", \"\")\n",
    "                         .replace('\"',\"\")).rstrip()\n",
    "    return clean_date_string.lstrip()\n",
    "\n",
    "s = clean_date('Week Ending September 04, 2021\"||||||||||||||||\\n')\n",
    "print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "September 04, 2021\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#export\n",
    "class ParishData:\n",
    "   \n",
    "    def __init__(self, parish, data, header):\n",
    "        self.parish = parish.replace(\" \",\"\").lower()\n",
    "        self.data = data\n",
    "        self.header = header\n",
    "        \n",
    "    def write_to_csv(self,output_directory:str):\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        try:\n",
    "            os.mkdir(f\"{output_directory}/{report_date}\") \n",
    "        except OSError as error: \n",
    "            print(f\"{output_directory}/{report_date} already exists,not recreating\")      \n",
    "\n",
    "        self.data.insert(0,self.header)\n",
    "        df = pd.DataFrame(self.data)\n",
    "        df.to_csv(f\"{output_directory}/{report_date}/{self.parish}_{report_date}.csv\",sep=\"|\" ,index=False, header=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.parish}: {self.data[:12]}\" "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#export\n",
    "def flatten_list(lst):\n",
    "    flat_list = [item for sublist in lst for item in sublist] \n",
    "    return flat_list \n",
    "\n",
    "def remove_empty_strings_from_list(lst):\n",
    "    _list = ' '.join(lst).split()\n",
    "    return _list \n",
    "\n",
    "def create_parish_data(data_list,data_date,header,parish):\n",
    "    result = ParishData(parish, data_list, header)    \n",
    "    return result\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'St.Thomas'}: [[1, 2, 3, 4], [5, 6, 7, 8]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#export\n",
    "def split_data(data_list,idx,parish_list,date):\n",
    "    idx = 7\n",
    "    r = []\n",
    "    p0_data_list = []\n",
    "    p1_data_list = []\n",
    "    for d in data_list: \n",
    "        d = list(map( lambda s: s.replace('\\n',''), d ))\n",
    "        d = list(map(str.lower, d))\n",
    "        if len(parish_list) == 2:\n",
    "            p1 = parish_list[0]\n",
    "            p2 = parish_list[1]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            d2 = d[idx:]\n",
    "            # let add the variety\n",
    "            d2[:0] = [d[1]]\n",
    "            # and the commodity\n",
    "            d2[:0] = [d[0]]\n",
    "            d2[:0] =  [p2]\n",
    "            d2[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "            p1_data_list.extend([d2])\n",
    "            x = f\"{len(p0_data_list[0])}, {p0_data_list}\",f\"{len(p1_data_list[0])}, {p1_data_list}\"\n",
    "            \n",
    "        else: \n",
    "            p1 = parish_list[0]\n",
    "            d1 = d[:idx]\n",
    "            d1[:0] = [p1]\n",
    "            d1[:0] = [date]\n",
    "            p0_data_list.extend([d1])\n",
    "    if len(parish_list) == 2:\n",
    "        result = p0_data_list, p1_data_list\n",
    "    else: \n",
    "        result = p0_data_list\n",
    "        \n",
    "    return  result\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#export\n",
    "def process_group(group,header):\n",
    "        data_group_list = []\n",
    "        result = []\n",
    "        parishes_no_space  = {}\n",
    "        idx = 0\n",
    "        \n",
    "        parish_list = [\"Manchester\",\n",
    "                       \"St.Andrew\",\n",
    "                       \"St.Catherine\",\n",
    "                       \"Clarendon\",\n",
    "                       \"St.Elizabeth\",\n",
    "                       \"Westmoreland\",\n",
    "                       \"Hanover\",\n",
    "                       \"St.James\",\n",
    "                       \"Trelawny\",\n",
    "                       \"St.Ann\",\n",
    "                       \"St.Mary\",\n",
    "                       \"Portland\",\n",
    "                       \"St.Thomas\"]   \n",
    "        parishes = group[0]\n",
    "        parishes = parishes.split(\"|\")\n",
    "        for p in parishes: \n",
    "            if len(p) > 5:\n",
    "                parishes_no_space[idx]  = p\n",
    "                idx = idx + 1\n",
    "        # there is space between the manchester and st.andrew heading\n",
    "        # and thier data, this space is not between the other headers \n",
    "        # and thier data :-) \n",
    "        offset =  5 if len(group) == 55 else 3        \n",
    "        \n",
    "        data_list = get_data(group[offset:],len(parishes_no_space)) \n",
    "             \n",
    "        \n",
    "        if len(parishes_no_space) == 2: \n",
    "            p1 = parishes_no_space[0]\n",
    "            p2 = parishes_no_space[1]\n",
    "            # split the data\n",
    "            p1_data, p2_data = split_data(data_list,idx,[p1,p2],report_date)\n",
    "            parish_data_1 = create_parish_data(p1_data,report_date , header,p1)\n",
    "            parish_data_2 = create_parish_data(p2_data,report_date , header,p2)\n",
    "            result.extend([parish_data_1,parish_data_2])\n",
    "        else:\n",
    "            # we only have one parish \n",
    "            p1 = parishes_no_space[0]\n",
    "            p1_data = split_data(data_list,idx,[p1],report_date)\n",
    "            parish_data_1 = create_parish_data( p1_data ,report_date, header,p1)\n",
    "            result.extend([parish_data_1])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "group = []  \n",
    "header = ['date', 'parish', 'Commodity', 'Variety Source', \n",
    "'Low', 'High', '\"Most Frequent\"', 'Supply', 'Grade', 'Low', \n",
    "'High', '\"Most Frequent\"', 'Supply', 'Grade']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#export\n",
    "global report_date  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "#export\n",
    "def run(input_path:str, output_directory:str):\n",
    "    global report_date\n",
    "    path = input_path\n",
    "    with open(path) as file:\n",
    "        groups =[]\n",
    "        processed_groups = []\n",
    "        current_group =[]\n",
    "        \n",
    "        group_boundary_str = \"Prepared on\"\n",
    "        doc_lines = file.readlines()\n",
    "        for line in doc_lines:\n",
    "            if \"Ministry of Industry\" in line:\n",
    "                continue\n",
    "            if \"Fisheries\" in line:\n",
    "                continue\n",
    "            if \"Commerce, Agriculture\" in line:\n",
    "                continue    \n",
    "            if \"Prepared on\" in line:\n",
    "                groups.append(current_group)\n",
    "                current_group = []\n",
    "                continue\n",
    "            if len(line.replace(\"|\", \"\").strip()) == 0:\n",
    "                continue \n",
    "            if  \"Week Ending\" in line:\n",
    "                report_date = clean_date(line)\n",
    "                report_date =format_date(report_date)\n",
    "                continue\n",
    "            current_group.append(line)\n",
    "    \n",
    "    headers = get_headers(groups[0][1:5])\n",
    "        \n",
    "    for group in groups:\n",
    "        group = process_group(group, headers)\n",
    "        processed_groups.append(group)\n",
    "        \n",
    "    flat_list = [item for sublist in processed_groups for item in sublist]    \n",
    "    for p in flat_list:\n",
    "        p.write_to_csv(output_directory)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#export\n",
    "@call_parse\n",
    "def main(input_path:Param(\"The farmgate file path\", str),\n",
    "         output_folder:Param(\"where the converted file should be written\", str),\n",
    "      ):\n",
    "    \"Clean up the input file and generates individual parish farm gate prices in the specified output folder\"\n",
    "    print(f\"input path:{input_path}\")\n",
    "    run(input_path, output_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "notebook2script()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted farmgate_data_viz.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}